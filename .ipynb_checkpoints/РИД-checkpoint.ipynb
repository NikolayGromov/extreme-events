{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f056f4b",
   "metadata": {},
   "source": [
    "Создаем хаотическую систему Льенара и задаем параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376de272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lienard(t, X):\n",
    "    x, y = X\n",
    "    return [y,\n",
    "          -a*x*y - gm * x - b*x**3 + F*np.sin(w*t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f35ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.45\n",
    "b = 0.5\n",
    "gm = - 0.5\n",
    "F = 0.2\n",
    "w = 0.6423"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ea6eb",
   "metadata": {},
   "source": [
    "Загружаем временной ряд этой системы, собираем тренировочную и тестовые выборки, нормируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"./lienard_intermittency.dat\")\n",
    "train = data[:, 1][:45000]\n",
    "test =  data[:, 1][45000:]\n",
    "\n",
    "mean = train.mean()\n",
    "std = train.std()\n",
    "\n",
    "train_norm = (train - mean)/std\n",
    "test_norm = (test - mean)/std\n",
    "\n",
    "train_norm = torch.FloatTensor(train_norm).view(-1)\n",
    "test_norm = torch.FloatTensor(test_norm).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1ceef",
   "metadata": {},
   "source": [
    "Для рекуррентных нейронных сетей выбирается окно предыдущих временных шагов для предсказания следующего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 20\n",
    "\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "train_inout_seq = create_inout_sequences(train_norm, train_window)\n",
    "test_inout_seq = create_inout_sequences(test_norm, train_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f56e5",
   "metadata": {},
   "source": [
    "Для параллельных вычислений и для ускорения сходимости обучать будем по батчам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5abce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_inout_seq, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_inout_seq, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f0a46",
   "metadata": {},
   "source": [
    "Рекуррентная LSTM модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=32, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(hidden_layer_size, hidden_size=self.hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(num_layers*hidden_layer_size, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # layer 1\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # Floating\n",
    "        x = h_n.permute(1, 0, 2).reshape(batchsize, -1) \n",
    "        \n",
    "        # layer 2\n",
    "        x = self.dropout(x)\n",
    "        predictions = self.linear_2(x)\n",
    "        return predictions[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82b75f",
   "metadata": {},
   "source": [
    "Создание модели, отправление ее для вычислений на видеокарту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size=1, hidden_layer_size=100, num_layers=2, output_size=1, dropout=0.2)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354118e",
   "metadata": {},
   "source": [
    "Функция, прогоняющая одну эпоху"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, dataloader, is_training=False):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for idx, (x, y) in enumerate(dataloader):\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        x = torch.reshape(x, (64, 20, 1)).to('cuda')\n",
    "        y = y.view(-1).to('cuda')\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out.contiguous(), y.contiguous())\n",
    "\n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss += (loss.detach().item() / batchsize)\n",
    "\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc60892",
   "metadata": {},
   "source": [
    "Различные функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c19222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gevl_loss(y_pred, y_true):\n",
    "    u = y_pred - y_true  \n",
    "    return (1-torch.exp(-u**2))*u**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Frechet_loss(y_pred, y_true, alpha=13, s=1.7):\n",
    "    u = torch.abs(y_pred - y_true)\n",
    "    K = alpha/s*((u+s*(alpha/(1+alpha))**(1/alpha))/s)**(-1-alpha)\n",
    "    K_exp = ((u+s*(alpha/(1+alpha))**(1/alpha))/s)**-alpha\n",
    "    return (-torch.log(K) + K_exp).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a49542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Asymmetric_loss(y_pred, y_true):\n",
    "    y_plus = torch.abs(y_true)\n",
    "    y_p_plus = torch.abs(y_pred)\n",
    "    y_max = torch.maximum(y_plus, y_p_plus)\n",
    "    return ((y_plus - y_max) ** 2).mean() + 3 * ((y_p_plus - y_max) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cbdbe3",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-9)\n",
    "lr = 0.001\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "# begin training\n",
    "for epoch in range(175): \n",
    "    if epoch > 40:\n",
    "        lr = 0.0005\n",
    "    if epoch > 100:\n",
    "        lr = 0.0001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-9)    \n",
    "    loss_train = run_epoch(model, train_dataloader, is_training=True)\n",
    "    loss_val = run_epoch(model, test_dataloader)\n",
    "    losses_train.append(loss_train)\n",
    "    losses_test.append(loss_val)\n",
    "    \n",
    "    clear_output(True)\n",
    "    fig = plt.figure(figsize=(10, 9))\n",
    "    \n",
    "    ax_1 = fig.add_subplot(2, 1, 1)\n",
    "    ax_2 = fig.add_subplot(2, 1, 2)\n",
    "    ax_1.set_title('train')\n",
    "    ax_1.plot(losses_train)\n",
    "    ax_2.set_title('test')\n",
    "    ax_2.plot(losses_test)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Epoch[{}/{}] | loss train:{:.6f}, test:{:.6f}'\n",
    "              .format(epoch+1, 175, loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d969e",
   "metadata": {},
   "source": [
    "Функция, выдающая ошибки предсказаний на k шагов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a288a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRmse(model, train_dataloader, val_dataloader, test, std, mean):\n",
    "    model.eval()\n",
    "\n",
    "    rmse = []\n",
    "\n",
    "    for k in range(1, 20):\n",
    "        test_right_part = (len(test)- 20)%64\n",
    "        predicted_val = np.array([])\n",
    "        for idx, (x, y) in enumerate(val_dataloader):\n",
    "            x = torch.reshape(x, (64, 20, 1)).to('cuda')\n",
    "            cur_x = x\n",
    "            for _ in range(k):\n",
    "                out = model(cur_x.to('cuda'))\n",
    "                cur_x = torch.hstack((cur_x[:, 1:], torch.reshape(out, (64, 1, 1))))\n",
    "            predicted_val = np.concatenate((predicted_val, cur_x[:, -1, 0].cpu().detach().numpy()))\n",
    "        if k == 1:\n",
    "            r = (((np.array(predicted_val)*std+mean - np.array(test[20:-test_right_part]))**2).mean())**0.5\n",
    "        else:\n",
    "            r = (((np.array(predicted_val[:-k+1])*std+mean - np.array(test[20+k-1:-test_right_part]))**2).mean())**0.5\n",
    "        rmse.append(r)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fb6fe",
   "metadata": {},
   "source": [
    "Функция, отрисовывающая предсказания на k шагов и возвращающая их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowPredict(model1, k, train_dataloader, val_dataloader, test_norm):\n",
    "    test_right_part = (len(test)- 20)%64\n",
    "    predicted_val = np.array([])\n",
    "    for idx, (x, y) in enumerate(val_dataloader):\n",
    "        x = torch.reshape(x, (64, 20, 1)).to('cuda')\n",
    "        cur_x = x\n",
    "        for _ in range(k):\n",
    "            out = model1(cur_x.to('cuda'))\n",
    "            cur_x = torch.hstack((cur_x[:, 1:], torch.reshape(out, (64, 1, 1))))\n",
    "        predicted_val = np.concatenate((predicted_val, cur_x[:, -1, 0].cpu().detach().numpy()))\n",
    "        \n",
    "        \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "        \n",
    "    ax_1 = fig.add_subplot(2, 1, 1)\n",
    "    ax_1.plot(test_norm[20+k-1:], label='true')\n",
    "    if k == 1:\n",
    "        ax_1.plot(predicted_val[:],  linestyle = '--', label='predicted')\n",
    "    else:\n",
    "        ax_1.plot(predicted_val[:-k+1],  linestyle = '--', label='predicted')\n",
    "    ax_1.set_title(\"RMSE k = {0}\".format(k))\n",
    "    ax_1.legend()\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a0ca0",
   "metadata": {},
   "source": [
    "Резервуарные вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "trainLen = 45000\n",
    "testLen = 4999\n",
    "initLen = 0\n",
    "\n",
    "\n",
    "# generate the ESN reservoir\n",
    "inSize = outSize = 1\n",
    "resSize = 400\n",
    "a = 0.5 # leaking rate\n",
    "np.random.seed(42)\n",
    "Win = (np.random.rand(resSize,1+inSize) - 0.5) * 1\n",
    "W = np.random.rand(resSize,resSize) - 0.5 \n",
    "# normalizing and setting spectral radius (correct, slow):\n",
    "print('Computing spectral radius...')\n",
    "rhoW = max(abs(linalg.eig(W)[0]))\n",
    "print('done.')\n",
    "W *= 0.001 / rhoW\n",
    "\n",
    "# allocated memory for the design (collected states) matrix\n",
    "X = np.zeros((1+inSize+resSize,trainLen-initLen))\n",
    "# set the corresponding target matrix directly\n",
    "Yt = data[None,initLen+1:trainLen+1] \n",
    "\n",
    "# run the reservoir with the data and collect X\n",
    "x = np.zeros((resSize,1))\n",
    "for t in range(trainLen):\n",
    "    u = data[t]\n",
    "    x = (1-a)*x + a*np.tanh(np.dot(Win, np.vstack((1,u))) + np.dot( W, x ) )\n",
    "    if t >= initLen:\n",
    "        X[:,t-initLen] = np.vstack((1,u,x))[:,0]\n",
    "reservoir_end = x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1246024",
   "metadata": {},
   "source": [
    "Оптимизация весов Wout и подсчет mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4de5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1e-8  # regularization coefficient\n",
    "\n",
    "Wout = linalg.solve( np.dot(X,X.T) + reg*np.eye(1+inSize+resSize), \n",
    "    np.dot(X,Yt.T) ).T\n",
    "\n",
    "# run the trained ESN in a generative mode. no need to initialize here, \n",
    "# because x is initialized with training data and we continue from there.\n",
    "Y = np.zeros((outSize,testLen))\n",
    "u = data[trainLen]\n",
    "for t in range(testLen):\n",
    "    x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "    y = np.dot( Wout, np.vstack((1,u,x)) )\n",
    "    Y[:,t] = y\n",
    "    # generative mode:\n",
    "    #u = y\n",
    "    ## this would be a predictive mode:\n",
    "    u = data[trainLen+t+1] \n",
    "\n",
    "# compute MSE for the first errorLen time steps\n",
    "errorLen = 500\n",
    "mse = sum( np.square( data[trainLen+1:trainLen+errorLen+1] - \n",
    "    Y[0,0:errorLen] ) ) / errorLen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17134666",
   "metadata": {},
   "source": [
    "Полносвязная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef99f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "          nn.Linear(1, 100),\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(100, 1)\n",
    "        )\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9ff02",
   "metadata": {},
   "source": [
    "Тренировочные и тестовые данные для полносвязной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.FloatTensor(train).view(-1 ,1)\n",
    "test = torch.FloatTensor(test).view(-1 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155dcfc",
   "metadata": {},
   "source": [
    "Разбиение на признаки и таргеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[:-1]\n",
    "Y = train[1:]\n",
    "X.size() == Y.size()\n",
    "\n",
    "X_t = test[:-1]\n",
    "Y_t = test[1:]\n",
    "X_t.size() == Y_t.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992186a3",
   "metadata": {},
   "source": [
    "Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2500\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "losses = []\n",
    "val_losses = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    #train\n",
    "    epoch_loss = []\n",
    "    val_epoch_loss = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_pred = model(X.to('cuda'))\n",
    "\n",
    "    single_loss = nn.MSELoss()(y_pred, Y.to('cuda'))\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_loss.append(single_loss.item())\n",
    "    \n",
    "    #valid\n",
    "    model.eval()\n",
    "    y_pred = model(X_t.to('cuda'))\n",
    "\n",
    "    single_loss = nn.MSELoss()(y_pred, Y_t.to('cuda'))\n",
    "    val_epoch_loss.append(single_loss.item())    \n",
    "    \n",
    "    clear_output(True)\n",
    "    losses.append(np.mean(epoch_loss))\n",
    "    val_losses.append(np.mean(val_epoch_loss))\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 9))\n",
    "    \n",
    "    ax_1 = fig.add_subplot(2, 1, 1)\n",
    "    ax_2 = fig.add_subplot(2, 1, 2)\n",
    "    ax_1.set_title('train')\n",
    "    ax_1.plot(losses)\n",
    "    ax_2.set_title('test')\n",
    "    ax_2.plot(val_losses)\n",
    "    plt.show()\n",
    "    print(losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e7385",
   "metadata": {},
   "source": [
    "Загрузка ответов моделей для ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = np.load('./FFNN_lienar.npy')\n",
    "ffnn = ffnn[19:4947]\n",
    "ffnn = ffnn.reshape(4928)\n",
    "\n",
    "rc = np.load('./RC_lienar.npy')\n",
    "rc = rc[:, 19:4947]\n",
    "rc = rc.reshape(4928)\n",
    "\n",
    "lstm = np.load('./LSTM_lienar.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a29a100",
   "metadata": {},
   "source": [
    "Модель для нахождения весов в ансамбле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fd7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "          nn.Linear(3, 1),\n",
    "        )\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3183d",
   "metadata": {},
   "source": [
    "Тренировка ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e387a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "losses = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    epoch_loss = []\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_pred = model(torch.FloatTensor(np.vstack((lstm2,rc,ffnn)).T).to('cuda'))\n",
    "\n",
    "    single_loss = nn.MSELoss()(y_pred, test[20:4948].to('cuda'))\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_loss.append(single_loss.item())\n",
    "\n",
    "        \n",
    "    clear_output(True)\n",
    "    losses.append(np.mean(epoch_loss))\n",
    "    plt.title(\"loss on train\")\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "    print(losses[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
