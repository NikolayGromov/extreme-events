{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189d1484-1773-4765-9161-2f77ff7fc4cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:16:15.628285Z",
     "start_time": "2024-07-14T10:16:15.580953Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'audio_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mel \u001b[38;5;28;01mas\u001b[39;00m librosa_mel_fn\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maudio_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_range_compression\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maudio_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_range_decompression\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STFT\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'audio_processing'"
     ]
    }
   ],
   "source": [
    "from librosa.filters import mel as librosa_mel_fn\n",
    "from math import sqrt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "from audio_processing import dynamic_range_compression\n",
    "from audio_processing import dynamic_range_decompression\n",
    "from stft import STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a477cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T09:43:38.519258Z",
     "start_time": "2024-07-14T09:43:38.511363Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_mask_from_lengths(lengths):\n",
    "    r\"\"\"Returns a binary mask based on ``lengths``. The ``i``-th row and ``j``-th column of the mask\n",
    "    is ``1`` if ``j`` is smaller than ``i``-th element of ``lengths.\n",
    "\n",
    "    Args:\n",
    "        lengths (Tensor): The length of each element in the batch, with shape (n_batch, ).\n",
    "\n",
    "    Returns:\n",
    "        mask (Tensor): The binary mask, with shape (n_batch, max of ``lengths``).\n",
    "    \"\"\"\n",
    "    max_len = torch.max(lengths).item()\n",
    "    ids = torch.arange(0, max_len, device=lengths.device, dtype=lengths.dtype)\n",
    "    mask = (ids < lengths.unsqueeze(1)).byte()\n",
    "    mask = torch.le(mask, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e3c6d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T09:45:58.365638Z",
     "start_time": "2024-07-14T09:45:58.356959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.LongTensor([3, 4, 4, 4])\n",
    "_get_mask_from_lengths(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1254124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T09:44:31.475512Z",
     "start_time": "2024-07-14T09:44:31.443748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46779f96-d5bb-44e8-a701-dac28477f89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2307587/513654267.py:1: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = librosa_mel_fn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.        ,  0.01661682,  0.03323364, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_basis = librosa_mel_fn(\n",
    "            sr=256, n_fft=256, n_mels=32, fmin=0, fmax=256)\n",
    "mel_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d826a73-2d9f-4ade-b230-fd9a5e6c30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpectrogramCompressing(spectrogram, windowfunc):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a763e3-3a5c-46c6-8830-a7f59895d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LinearNorm(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, bias=True, w_init_gain='linear'):\n",
    "        super(LinearNorm, self).__init__()\n",
    "        self.linear_layer = torch.nn.Linear(in_dim, out_dim, bias=bias)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            self.linear_layer.weight,\n",
    "            gain=torch.nn.init.calculate_gain(w_init_gain))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "\n",
    "class ConvNorm(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1,\n",
    "                 padding=None, dilation=1, bias=True, w_init_gain='linear'):\n",
    "        super(ConvNorm, self).__init__()\n",
    "        if padding is None:\n",
    "            assert(kernel_size % 2 == 1)\n",
    "            padding = int(dilation * (kernel_size - 1) / 2)\n",
    "\n",
    "        self.conv = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                    kernel_size=kernel_size, stride=stride,\n",
    "                                    padding=padding, dilation=dilation,\n",
    "                                    bias=bias)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n",
    "\n",
    "    def forward(self, signal):\n",
    "        conv_signal = self.conv(signal)\n",
    "        return conv_signal\n",
    "\n",
    "\n",
    "class TacotronSTFT(torch.nn.Module):\n",
    "    def __init__(self, filter_length=1024, hop_length=256, win_length=1024,\n",
    "                 n_mel_channels=80, sampling_rate=22050, mel_fmin=0.0,\n",
    "                 mel_fmax=8000.0):\n",
    "        super(TacotronSTFT, self).__init__()\n",
    "        self.n_mel_channels = n_mel_channels\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.stft_fn = STFT(filter_length, hop_length, win_length)\n",
    "        mel_basis = librosa_mel_fn(\n",
    "            sampling_rate, filter_length, n_mel_channels, mel_fmin, mel_fmax)\n",
    "        mel_basis = torch.from_numpy(mel_basis).float()\n",
    "        self.register_buffer('mel_basis', mel_basis)\n",
    "\n",
    "    def spectral_normalize(self, magnitudes):\n",
    "        output = dynamic_range_compression(magnitudes)\n",
    "        return output\n",
    "\n",
    "    def spectral_de_normalize(self, magnitudes):\n",
    "        output = dynamic_range_decompression(magnitudes)\n",
    "        return output\n",
    "\n",
    "    def mel_spectrogram(self, y):\n",
    "        \"\"\"Computes mel-spectrograms from a batch of waves\n",
    "        PARAMS\n",
    "        ------\n",
    "        y: Variable(torch.FloatTensor) with shape (B, T) in range [-1, 1]\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        mel_output: torch.FloatTensor of shape (B, n_mel_channels, T)\n",
    "        \"\"\"\n",
    "        assert(torch.min(y.data) >= -1)\n",
    "        assert(torch.max(y.data) <= 1)\n",
    "\n",
    "        magnitudes, phases = self.stft_fn.transform(y)\n",
    "        magnitudes = magnitudes.data\n",
    "        mel_output = torch.matmul(self.mel_basis, magnitudes)\n",
    "        mel_output = self.spectral_normalize(mel_output)\n",
    "        return mel_output\n",
    "\n",
    "class LocationLayer(nn.Module):\n",
    "    def __init__(self, attention_n_filters, attention_kernel_size,\n",
    "                 attention_dim):\n",
    "        super(LocationLayer, self).__init__()\n",
    "        padding = int((attention_kernel_size - 1) / 2)\n",
    "        self.location_conv = ConvNorm(2, attention_n_filters,\n",
    "                                      kernel_size=attention_kernel_size,\n",
    "                                      padding=padding, bias=False, stride=1,\n",
    "                                      dilation=1)\n",
    "        self.location_dense = LinearNorm(attention_n_filters, attention_dim,\n",
    "                                         bias=False, w_init_gain='tanh')\n",
    "\n",
    "    def forward(self, attention_weights_cat):\n",
    "        processed_attention = self.location_conv(attention_weights_cat)\n",
    "        processed_attention = processed_attention.transpose(1, 2)\n",
    "        processed_attention = self.location_dense(processed_attention)\n",
    "        return processed_attention\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, attention_rnn_dim, embedding_dim, attention_dim,\n",
    "                 attention_location_n_filters, attention_location_kernel_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.query_layer = LinearNorm(attention_rnn_dim, attention_dim,\n",
    "                                      bias=False, w_init_gain='tanh')\n",
    "        self.memory_layer = LinearNorm(embedding_dim, attention_dim, bias=False,\n",
    "                                       w_init_gain='tanh')\n",
    "        self.v = LinearNorm(attention_dim, 1, bias=False)\n",
    "        self.location_layer = LocationLayer(attention_location_n_filters,\n",
    "                                            attention_location_kernel_size,\n",
    "                                            attention_dim)\n",
    "        self.score_mask_value = -float(\"inf\")\n",
    "\n",
    "    def get_alignment_energies(self, query, processed_memory,\n",
    "                               attention_weights_cat):\n",
    "        \"\"\"\n",
    "        PARAMS\n",
    "        ------\n",
    "        query: decoder output (batch, n_mel_channels * n_frames_per_step)\n",
    "        processed_memory: processed encoder outputs (B, T_in, attention_dim)\n",
    "        attention_weights_cat: cumulative and prev. att weights (B, 2, max_time)\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        alignment (batch, max_time)\n",
    "        \"\"\"\n",
    "\n",
    "        processed_query = self.query_layer(query.unsqueeze(1))\n",
    "        processed_attention_weights = self.location_layer(attention_weights_cat)\n",
    "        energies = self.v(torch.tanh(\n",
    "            processed_query + processed_attention_weights + processed_memory))\n",
    "\n",
    "        energies = energies.squeeze(-1)\n",
    "        return energies\n",
    "\n",
    "    def forward(self, attention_hidden_state, memory, processed_memory,\n",
    "                attention_weights_cat, mask):\n",
    "        \"\"\"\n",
    "        PARAMS\n",
    "        ------\n",
    "        attention_hidden_state: attention rnn last output\n",
    "        memory: encoder outputs\n",
    "        processed_memory: processed encoder outputs\n",
    "        attention_weights_cat: previous and cummulative attention weights\n",
    "        mask: binary mask for padded data\n",
    "        \"\"\"\n",
    "        alignment = self.get_alignment_energies(\n",
    "            attention_hidden_state, processed_memory, attention_weights_cat)\n",
    "\n",
    "        if mask is not None:\n",
    "            alignment.data.masked_fill_(mask, self.score_mask_value)\n",
    "\n",
    "        attention_weights = F.softmax(alignment, dim=1)\n",
    "        attention_context = torch.bmm(attention_weights.unsqueeze(1), memory)\n",
    "        attention_context = attention_context.squeeze(1)\n",
    "\n",
    "        return attention_context, attention_weights\n",
    "\n",
    "\n",
    "class Prenet(nn.Module):\n",
    "    def __init__(self, in_dim, sizes):\n",
    "        super(Prenet, self).__init__()\n",
    "        in_sizes = [in_dim] + sizes[:-1]\n",
    "        self.layers = nn.ModuleList(\n",
    "            [LinearNorm(in_size, out_size, bias=False)\n",
    "             for (in_size, out_size) in zip(in_sizes, sizes)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.layers:\n",
    "            x = F.dropout(F.relu(linear(x)), p=0.2, training=True) #was 0.5\n",
    "        return x\n",
    "\n",
    "\n",
    "class Postnet(nn.Module):\n",
    "    \"\"\"Postnet\n",
    "        - Five 1-d convolution with 512 channels and kernel size 5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super(Postnet, self).__init__()\n",
    "        self.convolutions = nn.ModuleList()\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                ConvNorm(hparams.n_mel_channels, hparams.postnet_embedding_dim,\n",
    "                         kernel_size=hparams.postnet_kernel_size, stride=1,\n",
    "                         padding=int((hparams.postnet_kernel_size - 1) / 2),\n",
    "                         dilation=1, w_init_gain='tanh'),\n",
    "                nn.BatchNorm1d(hparams.postnet_embedding_dim))\n",
    "        )\n",
    "\n",
    "        for i in range(1, hparams.postnet_n_convolutions - 1):\n",
    "            self.convolutions.append(\n",
    "                nn.Sequential(\n",
    "                    ConvNorm(hparams.postnet_embedding_dim,\n",
    "                             hparams.postnet_embedding_dim,\n",
    "                             kernel_size=hparams.postnet_kernel_size, stride=1,\n",
    "                             padding=int((hparams.postnet_kernel_size - 1) / 2),\n",
    "                             dilation=1, w_init_gain='tanh'),\n",
    "                    nn.BatchNorm1d(hparams.postnet_embedding_dim))\n",
    "            )\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                ConvNorm(hparams.postnet_embedding_dim, hparams.n_mel_channels,\n",
    "                         kernel_size=hparams.postnet_kernel_size, stride=1,\n",
    "                         padding=int((hparams.postnet_kernel_size - 1) / 2),\n",
    "                         dilation=1, w_init_gain='linear'),\n",
    "                nn.BatchNorm1d(hparams.n_mel_channels))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.convolutions) - 1):\n",
    "            x = F.dropout(torch.tanh(self.convolutions[i](x)), 0.2, self.training) # was 0.5\n",
    "        x = F.dropout(self.convolutions[-1](x), 0.2, self.training) # was 0.5\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder module:\n",
    "        - Three 1-d convolution banks\n",
    "        - Bidirectional LSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        convolutions = []\n",
    "        for _ in range(hparams.encoder_n_convolutions):\n",
    "            conv_layer = nn.Sequential(\n",
    "                ConvNorm(hparams.encoder_embedding_dim,\n",
    "                         hparams.encoder_embedding_dim,\n",
    "                         kernel_size=hparams.encoder_kernel_size, stride=1,\n",
    "                         padding=int((hparams.encoder_kernel_size - 1) / 2),\n",
    "                         dilation=1, w_init_gain='relu'),\n",
    "                nn.BatchNorm1d(hparams.encoder_embedding_dim))\n",
    "            convolutions.append(conv_layer)\n",
    "        self.convolutions = nn.ModuleList(convolutions)\n",
    "\n",
    "        self.lstm = nn.LSTM(hparams.encoder_embedding_dim,\n",
    "                            int(hparams.encoder_embedding_dim / 2), 1,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, input_lengths):\n",
    "        for conv in self.convolutions:\n",
    "            x = F.dropout(F.relu(conv(x)), 0.2, self.training) # was 0.5\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # pytorch tensor are not reversible, hence the conversion\n",
    "        input_lengths = input_lengths.cpu().numpy()\n",
    "        x = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, input_lengths, batch_first=True)\n",
    "\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(x)\n",
    "\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def inference(self, x):\n",
    "        for conv in self.convolutions:\n",
    "            x = F.relu(conv(x))#F.dropout(F.relu(conv(x)), 0.2, self.training) # was 0.5\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        self.n_frames_per_step = hparams.n_frames_per_step\n",
    "        self.encoder_embedding_dim = hparams.encoder_embedding_dim\n",
    "        self.attention_rnn_dim = hparams.attention_rnn_dim\n",
    "        self.decoder_rnn_dim = hparams.decoder_rnn_dim\n",
    "        self.prenet_dim = hparams.prenet_dim\n",
    "        self.max_decoder_steps = hparams.max_decoder_steps\n",
    "        self.gate_threshold = hparams.gate_threshold\n",
    "        self.p_attention_dropout = hparams.p_attention_dropout\n",
    "        self.p_decoder_dropout = hparams.p_decoder_dropout\n",
    "\n",
    "        self.prenet = Prenet(\n",
    "            hparams.n_mel_channels * hparams.n_frames_per_step,\n",
    "            [hparams.prenet_dim, hparams.prenet_dim])\n",
    "\n",
    "        self.attention_rnn = nn.LSTMCell(\n",
    "            hparams.prenet_dim + hparams.encoder_embedding_dim,\n",
    "            hparams.attention_rnn_dim)\n",
    "\n",
    "        self.attention_layer = Attention(\n",
    "            hparams.attention_rnn_dim, hparams.encoder_embedding_dim,\n",
    "            hparams.attention_dim, hparams.attention_location_n_filters,\n",
    "            hparams.attention_location_kernel_size)\n",
    "\n",
    "        self.decoder_rnn = nn.LSTMCell(\n",
    "            hparams.attention_rnn_dim + hparams.encoder_embedding_dim,\n",
    "            hparams.decoder_rnn_dim, 1)\n",
    "\n",
    "        self.linear_projection = LinearNorm(\n",
    "            hparams.decoder_rnn_dim + hparams.encoder_embedding_dim,\n",
    "            hparams.n_mel_channels * hparams.n_frames_per_step)\n",
    "\n",
    "        self.gate_layer = LinearNorm(\n",
    "            hparams.decoder_rnn_dim + hparams.encoder_embedding_dim, 1,\n",
    "            bias=True, w_init_gain='sigmoid')\n",
    "\n",
    "    def get_go_frame(self, memory):\n",
    "        \"\"\" Gets all zeros frames to use as first decoder input\n",
    "        PARAMS\n",
    "        ------\n",
    "        memory: decoder outputs\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        decoder_input: all zeros frames\n",
    "        \"\"\"\n",
    "        B = memory.size(0)\n",
    "        decoder_input = Variable(memory.data.new(\n",
    "            B, self.n_mel_channels * self.n_frames_per_step).zero_())\n",
    "        return decoder_input\n",
    "\n",
    "    def initialize_decoder_states(self, memory, mask):\n",
    "        \"\"\" Initializes attention rnn states, decoder rnn states, attention\n",
    "        weights, attention cumulative weights, attention context, stores memory\n",
    "        and stores processed memory\n",
    "        PARAMS\n",
    "        ------\n",
    "        memory: Encoder outputs\n",
    "        mask: Mask for padded data if training, expects None for inference\n",
    "        \"\"\"\n",
    "        B = memory.size(0)\n",
    "        MAX_TIME = memory.size(1)\n",
    "\n",
    "        self.attention_hidden = Variable(memory.data.new(\n",
    "            B, self.attention_rnn_dim).zero_())\n",
    "        self.attention_cell = Variable(memory.data.new(\n",
    "            B, self.attention_rnn_dim).zero_())\n",
    "\n",
    "        self.decoder_hidden = Variable(memory.data.new(\n",
    "            B, self.decoder_rnn_dim).zero_())\n",
    "        self.decoder_cell = Variable(memory.data.new(\n",
    "            B, self.decoder_rnn_dim).zero_())\n",
    "\n",
    "        self.attention_weights = Variable(memory.data.new(\n",
    "            B, MAX_TIME).zero_())\n",
    "        self.attention_weights_cum = Variable(memory.data.new(\n",
    "            B, MAX_TIME).zero_())\n",
    "        self.attention_context = Variable(memory.data.new(\n",
    "            B, self.encoder_embedding_dim).zero_())\n",
    "\n",
    "        self.memory = memory\n",
    "        self.processed_memory = self.attention_layer.memory_layer(memory)\n",
    "        self.mask = mask\n",
    "\n",
    "    def parse_decoder_inputs(self, decoder_inputs):\n",
    "        \"\"\" Prepares decoder inputs, i.e. mel outputs\n",
    "        PARAMS\n",
    "        ------\n",
    "        decoder_inputs: inputs used for teacher-forced training, i.e. mel-specs\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        inputs: processed decoder inputs\n",
    "\n",
    "        \"\"\"\n",
    "        # (B, n_mel_channels, T_out) -> (B, T_out, n_mel_channels)\n",
    "        decoder_inputs = decoder_inputs.transpose(1, 2)\n",
    "        decoder_inputs = decoder_inputs.view(\n",
    "            decoder_inputs.size(0),\n",
    "            int(decoder_inputs.size(1)/self.n_frames_per_step), -1)\n",
    "        # (B, T_out, n_mel_channels) -> (T_out, B, n_mel_channels)\n",
    "        decoder_inputs = decoder_inputs.transpose(0, 1)\n",
    "        return decoder_inputs\n",
    "\n",
    "    def parse_decoder_outputs(self, mel_outputs, gate_outputs, alignments):\n",
    "        \"\"\" Prepares decoder outputs for output\n",
    "        PARAMS\n",
    "        ------\n",
    "        mel_outputs:\n",
    "        gate_outputs: gate output energies\n",
    "        alignments:\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        mel_outputs:\n",
    "        gate_outpust: gate output energies\n",
    "        alignments:\n",
    "        \"\"\"\n",
    "        # (T_out, B) -> (B, T_out)\n",
    "        alignments = torch.stack(alignments).transpose(0, 1)\n",
    "        # (T_out, B) -> (B, T_out)\n",
    "        gate_outputs = torch.stack(gate_outputs).transpose(0, 1)\n",
    "        gate_outputs = gate_outputs.contiguous()\n",
    "        # (T_out, B, n_mel_channels) -> (B, T_out, n_mel_channels)\n",
    "        mel_outputs = torch.stack(mel_outputs).transpose(0, 1).contiguous()\n",
    "        # decouple frames per step\n",
    "        mel_outputs = mel_outputs.view(\n",
    "            mel_outputs.size(0), -1, self.n_mel_channels)\n",
    "        # (B, T_out, n_mel_channels) -> (B, n_mel_channels, T_out)\n",
    "        mel_outputs = mel_outputs.transpose(1, 2)\n",
    "\n",
    "        return mel_outputs, gate_outputs, alignments\n",
    "\n",
    "    def decode(self, decoder_input):\n",
    "        \"\"\" Decoder step using stored states, attention and memory\n",
    "        PARAMS\n",
    "        ------\n",
    "        decoder_input: previous mel output\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        mel_output:\n",
    "        gate_output: gate output energies\n",
    "        attention_weights:\n",
    "        \"\"\"\n",
    "        cell_input = torch.cat((decoder_input, self.attention_context), -1)\n",
    "        self.attention_hidden, self.attention_cell = self.attention_rnn(\n",
    "            cell_input, (self.attention_hidden, self.attention_cell))\n",
    "        self.attention_hidden = F.dropout(\n",
    "            self.attention_hidden, self.p_attention_dropout, self.training)\n",
    "\n",
    "        attention_weights_cat = torch.cat(\n",
    "            (self.attention_weights.unsqueeze(1),\n",
    "             self.attention_weights_cum.unsqueeze(1)), dim=1)\n",
    "        self.attention_context, self.attention_weights = self.attention_layer(\n",
    "            self.attention_hidden, self.memory, self.processed_memory,\n",
    "            attention_weights_cat, self.mask)\n",
    "\n",
    "        self.attention_weights_cum += self.attention_weights\n",
    "        decoder_input = torch.cat(\n",
    "            (self.attention_hidden, self.attention_context), -1)\n",
    "        self.decoder_hidden, self.decoder_cell = self.decoder_rnn(\n",
    "            decoder_input, (self.decoder_hidden, self.decoder_cell))\n",
    "        self.decoder_hidden = F.dropout(\n",
    "            self.decoder_hidden, self.p_decoder_dropout, self.training)\n",
    "\n",
    "        decoder_hidden_attention_context = torch.cat(\n",
    "            (self.decoder_hidden, self.attention_context), dim=1)\n",
    "        decoder_output = self.linear_projection(\n",
    "            decoder_hidden_attention_context)\n",
    "\n",
    "        gate_prediction = self.gate_layer(decoder_hidden_attention_context)\n",
    "        return decoder_output, gate_prediction, self.attention_weights\n",
    "\n",
    "    def forward(self, memory, decoder_inputs, memory_lengths):\n",
    "        \"\"\" Decoder forward pass for training\n",
    "        PARAMS\n",
    "        ------\n",
    "        memory: Encoder outputs\n",
    "        decoder_inputs: Decoder inputs for teacher forcing. i.e. mel-specs\n",
    "        memory_lengths: Encoder output lengths for attention masking.\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        mel_outputs: mel outputs from the decoder\n",
    "        gate_outputs: gate outputs from the decoder\n",
    "        alignments: sequence of attention weights from the decoder\n",
    "        \"\"\"\n",
    "\n",
    "        decoder_input = self.get_go_frame(memory).unsqueeze(0)\n",
    "        decoder_inputs = self.parse_decoder_inputs(decoder_inputs)\n",
    "        decoder_inputs = torch.cat((decoder_input, decoder_inputs), dim=0)\n",
    "        decoder_inputs = self.prenet(decoder_inputs)\n",
    "\n",
    "        self.initialize_decoder_states(\n",
    "            memory, mask=~get_mask_from_lengths(memory_lengths))\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = [], [], []\n",
    "        while len(mel_outputs) < decoder_inputs.size(0) - 1:\n",
    "            decoder_input = decoder_inputs[len(mel_outputs)]\n",
    "            mel_output, gate_output, attention_weights = self.decode(\n",
    "                decoder_input)\n",
    "            mel_outputs += [mel_output.squeeze(1)]\n",
    "            gate_outputs += [gate_output.squeeze(1)]\n",
    "            alignments += [attention_weights]\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.parse_decoder_outputs(\n",
    "            mel_outputs, gate_outputs, alignments)\n",
    "\n",
    "        return mel_outputs, gate_outputs, alignments\n",
    "\n",
    "    def inference(self, memory):\n",
    "        \"\"\" Decoder inference\n",
    "        PARAMS\n",
    "        ------\n",
    "        memory: Encoder outputs\n",
    "\n",
    "        RETURNS\n",
    "        -------\n",
    "        mel_outputs: mel outputs from the decoder\n",
    "        gate_outputs: gate outputs from the decoder\n",
    "        alignments: sequence of attention weights from the decoder\n",
    "        \"\"\"\n",
    "        decoder_input = self.get_go_frame(memory)\n",
    "\n",
    "        self.initialize_decoder_states(memory, mask=None)\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = [], [], []\n",
    "        while True:\n",
    "            decoder_input = self.prenet(decoder_input)\n",
    "            mel_output, gate_output, alignment = self.decode(decoder_input)\n",
    "\n",
    "            mel_outputs += [mel_output.squeeze(1)]\n",
    "            gate_outputs += [gate_output]\n",
    "            alignments += [alignment]\n",
    "\n",
    "            if torch.sigmoid(gate_output.data) > self.gate_threshold:\n",
    "                break\n",
    "            elif len(mel_outputs) == self.max_decoder_steps:\n",
    "                print(\"Warning! Reached max decoder steps\")\n",
    "                break\n",
    "\n",
    "            decoder_input = mel_output\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.parse_decoder_outputs(\n",
    "            mel_outputs, gate_outputs, alignments)\n",
    "\n",
    "        return mel_outputs, gate_outputs, alignments\n",
    "\n",
    "\n",
    "class Tacotron2(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        self.mask_padding = hparams.mask_padding\n",
    "        self.fp16_run = hparams.fp16_run\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        self.n_frames_per_step = hparams.n_frames_per_step\n",
    "        self.embedding = nn.Embedding(\n",
    "            hparams.n_symbols, hparams.symbols_embedding_dim)\n",
    "        std = sqrt(2.0 / (hparams.n_symbols + hparams.symbols_embedding_dim))\n",
    "        val = sqrt(3.0) * std  # uniform bounds for std\n",
    "        self.embedding.weight.data.uniform_(-val, val)\n",
    "        self.encoder = Encoder(hparams)\n",
    "        self.decoder = Decoder(hparams)\n",
    "        self.postnet = Postnet(hparams)\n",
    "\n",
    "    def parse_batch(self, batch):\n",
    "        text_padded, input_lengths, mel_padded, gate_padded, \\\n",
    "            output_lengths = batch\n",
    "        text_padded = to_gpu(text_padded).long()\n",
    "        input_lengths = to_gpu(input_lengths).long()\n",
    "        max_len = torch.max(input_lengths.data).item()\n",
    "        mel_padded = to_gpu(mel_padded).float()\n",
    "        gate_padded = to_gpu(gate_padded).float()\n",
    "        output_lengths = to_gpu(output_lengths).long()\n",
    "\n",
    "        return (\n",
    "            (text_padded, input_lengths, mel_padded, max_len, output_lengths),\n",
    "            (mel_padded, gate_padded))\n",
    "\n",
    "    def parse_output(self, outputs, output_lengths=None):\n",
    "        if self.mask_padding and output_lengths is not None:\n",
    "            mask = ~get_mask_from_lengths(output_lengths)\n",
    "            mask = mask.expand(self.n_mel_channels, mask.size(0), mask.size(1))\n",
    "            mask = mask.permute(1, 0, 2)\n",
    "\n",
    "            outputs[0].data.masked_fill_(mask, 0.0)\n",
    "            outputs[1].data.masked_fill_(mask, 0.0)\n",
    "            outputs[2].data.masked_fill_(mask[:, 0, :], 1e3)  # gate energies\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        text_inputs, text_lengths, mels, max_len, output_lengths = inputs\n",
    "        text_lengths, output_lengths = text_lengths.data, output_lengths.data\n",
    "\n",
    "        embedded_inputs = self.embedding(text_inputs).transpose(1, 2)\n",
    "\n",
    "        encoder_outputs = self.encoder(embedded_inputs, text_lengths)\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.decoder(\n",
    "            encoder_outputs, mels, memory_lengths=text_lengths)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_outputs, alignments],\n",
    "            output_lengths)\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        embedded_inputs = self.embedding(inputs).transpose(1, 2)\n",
    "        encoder_outputs = self.encoder.inference(embedded_inputs)\n",
    "        mel_outputs, gate_outputs, alignments = self.decoder.inference(\n",
    "            encoder_outputs)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        outputs = self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_outputs, alignments])\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ea7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!L\n",
    "N_SYMBOLS = 148\n",
    "SYMBOLS_EMBEDDING_DIM = 512\n",
    "N_MEL_CHANNELS = 80\n",
    "N_FRAMES_PER_STEP = 1\n",
    "ENCODER_EMBEDDING_DIM = 512\n",
    "ATTENTION_DIM = 128\n",
    "PRENET_DIM = 256\n",
    "ATTENTION_RNN_DIM = 1024\n",
    "ATTENTION_LOCATION_N_FILTERS = 32\n",
    "ATTENTION_LOCATION_KERNEL_SIZE = 31\n",
    "DECODER_RNN_DIM = 1024\n",
    "P_ATTENTION_DROPOUT = 0.1\n",
    "P_DECODER_DROPOUT = 0.1\n",
    "GATE_THRESHOLD = 0.5\n",
    "MAX_DECODER_STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e05698f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:20:45.246174Z",
     "start_time": "2024-07-14T10:20:45.184150Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearNorm(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, bias=True, w_init_gain='linear'):\n",
    "        super(LinearNorm, self).__init__()\n",
    "        self.linear_layer = torch.nn.Linear(in_dim, out_dim, bias=bias)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            self.linear_layer.weight,\n",
    "            gain=torch.nn.init.calculate_gain(w_init_gain))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "\n",
    "class ConvNorm(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1,\n",
    "                 padding=None, dilation=1, bias=True, w_init_gain='linear'):\n",
    "        super(ConvNorm, self).__init__()\n",
    "        if padding is None:\n",
    "            assert(kernel_size % 2 == 1)\n",
    "            padding = int(dilation * (kernel_size - 1) / 2)\n",
    "\n",
    "        self.conv = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                    kernel_size=kernel_size, stride=stride,\n",
    "                                    padding=padding, dilation=dilation,\n",
    "                                    bias=bias)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(\n",
    "            self.conv.weight, gain=torch.nn.init.calculate_gain(w_init_gain))\n",
    "\n",
    "    def forward(self, signal):\n",
    "        conv_signal = self.conv(signal)\n",
    "        return conv_signal\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder module:\n",
    "        - Three 1-d convolution banks\n",
    "        - Bidirectional LSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim=512):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        convolutions = []\n",
    "        for _ in range(3): #3 is param\n",
    "            conv_layer = nn.Sequential(\n",
    "                ConvNorm(hidden_dim,\n",
    "                         hidden_dim,\n",
    "                         kernel_size=5, stride=1, #kernel size is param\n",
    "                         padding=int((5 - 1) / 2), \n",
    "                         dilation=1, w_init_gain='relu'),\n",
    "                nn.BatchNorm1d(hidden_dim))\n",
    "            convolutions.append(conv_layer)\n",
    "        self.convolutions = nn.ModuleList(convolutions)\n",
    "\n",
    "        self.lstm = nn.LSTM(hidden_dim,\n",
    "                            int(hidden_dim / 2), 1,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self,  x):\n",
    "        for conv in self.convolutions:\n",
    "            x = F.dropout(F.relu(conv(x)), 0.2, self.training) # was 0.5\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "        #print(\"x\", x.size())\n",
    "\n",
    "        # pytorch tensor are not reversible, hence the conversion\n",
    "        \n",
    "        outputs, _ = self.lstm(x)\n",
    "        return outputs\n",
    "        \n",
    "class Prenet(nn.Module):\n",
    "    def __init__(self, in_dim, sizes):\n",
    "        super(Prenet, self).__init__()\n",
    "        in_sizes = [in_dim] + sizes[:-1]\n",
    "        self.layers = nn.ModuleList(\n",
    "            [LinearNorm(in_size, out_size, bias=False)\n",
    "             for (in_size, out_size) in zip(in_sizes, sizes)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.layers:\n",
    "            x = F.dropout(F.relu(linear(x)), 0.2, self.training) #was 0.5\n",
    "        return x\n",
    "    \n",
    "class Postnet(nn.Module):\n",
    "    \"\"\"Postnet\n",
    "        - Five 1-d convolution with 512 channels and kernel size 5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim=512):\n",
    "        super(Postnet, self).__init__()\n",
    "        self.convolutions = nn.ModuleList()\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                ConvNorm(80, hidden_dim,\n",
    "                         kernel_size=5, stride=1,\n",
    "                         padding=int((5 - 1) / 2),\n",
    "                         dilation=1, w_init_gain='tanh'),\n",
    "                nn.BatchNorm1d(hidden_dim))\n",
    "        )\n",
    "\n",
    "        for i in range(1, 5 - 1):\n",
    "            self.convolutions.append(\n",
    "                nn.Sequential(\n",
    "                    ConvNorm(hidden_dim,\n",
    "                             hidden_dim,\n",
    "                             kernel_size=5, stride=1,\n",
    "                             padding=int((5 - 1) / 2),\n",
    "                             dilation=1, w_init_gain='tanh'),\n",
    "                    nn.BatchNorm1d(hidden_dim))\n",
    "            )\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                ConvNorm(512, 80,\n",
    "                         kernel_size=5, stride=1,\n",
    "                         padding=int((5 - 1) / 2),\n",
    "                         dilation=1, w_init_gain='linear'),\n",
    "                nn.BatchNorm1d(80))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.convolutions) - 1):\n",
    "            x = F.dropout(torch.tanh(self.convolutions[i](x)), 0.2, self.training) # was 0.5\n",
    "        x = F.dropout(self.convolutions[-1](x), 0.2, self.training) # was 0.5\n",
    "\n",
    "        return x\n",
    "\n",
    "class Tacotron2(nn.Module):\n",
    "    def __init__(self, feature_dim=27, win_len=4000):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        self.win_len = win_len\n",
    "        \n",
    "        self.linear1 = nn.Conv1d(feature_dim, 512, 1) #512 is param\n",
    "        self.encoder = Encoder()\n",
    "        self.prenet = Prenet(80, [256, 256]) #params\n",
    "        self.attention_rnn = nn.LSTMCell(256 + 512, 1024) #prenet dim + encoder dim, hidden dim\n",
    "        \n",
    "        self.attention_v = nn.Linear(128, 1, bias=False) #param\n",
    "        self.attention_query = nn.Linear(1024, 128) #param\n",
    "        self.attention_memory = nn.Linear(512, 128) #param\n",
    "        self.attention_location_fc = nn.Linear(32, 128) # param\n",
    "        self.attention_location_conv = nn.Conv1d(2, 32, kernel_size=31, padding=int((31 - 1) / 2), bias=False) #params\n",
    "        \n",
    "        self.decoder_rnn = nn.LSTMCell(1024 + 512, 1024) #param\n",
    "        self.decoder_output_projection = nn.Linear(1024 + 512, 80)#param\n",
    "        \n",
    "        self.postnet = Postnet()#param\n",
    "        \n",
    "        \n",
    "        self.classifier1 = nn.Linear(80, 2)#param\n",
    "        self.classifier2 = nn.Linear(80, 2)#param\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        encoder_inputs = F.relu(self.linear1(inputs))\n",
    "        print(\"encoder_inputs\", encoder_inputs.size())\n",
    "        encoder_outputs = self.encoder(encoder_inputs)\n",
    "\n",
    "        B, N, *_ = encoder_outputs.size()\n",
    "        print(\"encoder_outputs\", encoder_outputs.size())\n",
    "\n",
    "        # prepare decoder for inference\n",
    "        # zero decoder states\n",
    "        attention_hidden = Variable(encoder_outputs.data.new(B, 1024).zero_()) #param\n",
    "        attention_cell = Variable(encoder_outputs.data.new(B, 1024).zero_())#param\n",
    "\n",
    "        decoder_hidden = Variable(encoder_outputs.data.new(B, 1024).zero_()) #param\n",
    "        decoder_cell = Variable(encoder_outputs.data.new(B, 1024).zero_()) #param\n",
    "\n",
    "        attention_weights = Variable(encoder_outputs.data.new(B, N).zero_())\n",
    "        attention_weights_sum = Variable(encoder_outputs.data.new(B, N).zero_())\n",
    "        attention_context = Variable(encoder_outputs.data.new(B, 512).zero_()) #param\n",
    "\n",
    "        # initialize memory\n",
    "        decoder_memory = encoder_outputs\n",
    "        decoder_processed_memory = self.attention_memory(decoder_memory)\n",
    "\n",
    "        # prepare all-zero input frame\n",
    "        decoder_input = Variable(encoder_outputs.data.new(\n",
    "            B, 80  #param\n",
    "        ).zero_())\n",
    "\n",
    "        # start inference\n",
    "        mel_outputs, alignments = [], []\n",
    "        print(\"decoder_input\", decoder_input.shape)\n",
    "        for _ in range(self.win_len):\n",
    "            # prenet   \n",
    "\n",
    "            prenet_output = self.prenet(decoder_input)\n",
    "            # attention\n",
    "\n",
    "            attention_rnn_input = torch.cat((prenet_output, attention_context), dim=-1)\n",
    "            print(\"prenet_output\", prenet_output.shape)\n",
    "            print(\"attention_context\", attention_context.shape)\n",
    "            print(\"attention_rnn_input\", attention_rnn_input.shape)\n",
    "\n",
    "            attention_hidden, attention_cell = self.attention_rnn(attention_rnn_input, (attention_hidden, attention_cell))\n",
    "            attention_hidden = F.dropout(attention_hidden, p = 0.2, training = False)\n",
    "\n",
    "            calculate_attention_query = self.attention_query(attention_hidden.unsqueeze(1))\n",
    "\n",
    "            attention_weights_cat = torch.cat((attention_weights.unsqueeze(1), attention_weights_sum.unsqueeze(1)), dim = 1)\n",
    "            attention_loc = self.attention_location_fc(self.attention_location_conv(attention_weights_cat).transpose(1, 2))\n",
    "\n",
    "            print(\"calculate_attention_query\", calculate_attention_query.shape)\n",
    "            print(\"decoder_processed_memory\", decoder_processed_memory.shape)\n",
    "            print(\"attention_loc\", attention_loc.shape)\n",
    "\n",
    "            #raise Exception(\"exit\")\n",
    "\n",
    "            energy = self.attention_v(torch.tanh(calculate_attention_query + attention_loc + decoder_processed_memory))\n",
    "            energy = energy.squeeze(-1)\n",
    "\n",
    "            attention_weights = F.softmax(energy, dim=1)\n",
    "            print(\"attention_weights\", attention_weights.shape)\n",
    "            \n",
    "            attention_context = torch.bmm(attention_weights.unsqueeze(1), decoder_memory)\n",
    "            print(\"attention_context\", attention_context.shape)\n",
    "            \n",
    "            attention_context = attention_context.squeeze(1)\n",
    "            print(\"attention_context2\", attention_context.shape)\n",
    "            \n",
    "\n",
    "            attention_weights_sum += attention_weights\n",
    "\n",
    "            # decoder rnn\n",
    "\n",
    "            decoder_rnn_input = torch.cat((attention_hidden, attention_context), dim=-1)\n",
    "            decoder_hidden, decoder_cell = self.decoder_rnn(decoder_rnn_input, (decoder_hidden, decoder_cell))\n",
    "            decoder_hidden = F.dropout(decoder_hidden, p = 0.2, training = False)\n",
    "            #..........\n",
    "\n",
    "            #..........\n",
    "            decoder_data = torch.cat((decoder_hidden, attention_context), dim=1)\n",
    "            decoder_output = self.decoder_output_projection(decoder_data)\n",
    "\n",
    "            #stop_gate_prediction = decoder_stop_gate_projection(decoder_data)\n",
    "\n",
    "            mel_outputs += [decoder_output.squeeze(1)]\n",
    "            alignments += [attention_weights]\n",
    "\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        alignments = torch.stack(alignments).transpose(0, 1)\n",
    "        #gate_outputs = torch.stack(gate_outputs).transpose(0, 1)\n",
    "        #gate_outputs = gate_outputs.contiguous()\n",
    "        mel_outputs = torch.stack(mel_outputs).transpose(0, 1).contiguous()\n",
    "        mel_outputs = mel_outputs.view(mel_outputs.size(0), -1, 80)\n",
    "        classifier_mel = self.classifier1(mel_outputs)\n",
    "        \n",
    "        mel_outputs = mel_outputs.transpose(1, 2)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        classifier_mel_postnet = self.classifier1(mel_outputs_postnet.transpose(1, 2))\n",
    "        \n",
    "\n",
    "        #synthesized_mels = mel_outputs + mel_outputs_postnet\n",
    "        return classifier_mel_postnet, classifier_mel, alignments\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18038567",
   "metadata": {},
   "source": [
    "Можно вынести только prenet из forward((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55c431e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T10:21:05.384276Z",
     "start_time": "2024-07-14T10:20:45.606276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs torch.Size([2, 512, 4000])\n",
      "encoder_outputs torch.Size([2, 4000, 512])\n",
      "decoder_input torch.Size([2, 80])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n",
      "prenet_output torch.Size([2, 256])\n",
      "attention_context torch.Size([2, 512])\n",
      "attention_rnn_input torch.Size([2, 768])\n",
      "calculate_attention_query torch.Size([2, 1, 128])\n",
      "decoder_processed_memory torch.Size([2, 4000, 128])\n",
      "attention_loc torch.Size([2, 4000, 128])\n",
      "attention_weights torch.Size([2, 4000])\n",
      "attention_context torch.Size([2, 1, 512])\n",
      "attention_context2 torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.FloatTensor(np.ones((2, 27, 4000)))\n",
    "taco = Tacotron2()\n",
    "post, preds, align = taco(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55c10916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T17:36:16.317598Z",
     "start_time": "2024-07-07T17:36:16.310106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4000, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eac550fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T17:36:24.800262Z",
     "start_time": "2024-07-07T17:36:24.791579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4000, 4000])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
