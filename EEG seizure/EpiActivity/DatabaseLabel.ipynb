{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d1260f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:02:11.119958Z",
     "start_time": "2024-12-03T12:02:08.572726Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.ticker as ticker\n",
    "from os import listdir\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30de59a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:02:14.329585Z",
     "start_time": "2024-12-03T12:02:14.322748Z"
    }
   },
   "outputs": [],
   "source": [
    "def ReadSignal(file_name): \n",
    "\n",
    "    f = pyedflib.EdfReader(file_name)\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sigbufs = np.zeros((20, f.getNSamples()[0])) #or n\n",
    "    \n",
    "    if n == 22:\n",
    "        for i in np.arange(19):\n",
    "            sigbufs[i, :] = f.readSignal(i)\n",
    "        sigbufs[19, :] = f.readSignal(21)\n",
    "    elif n == 23:\n",
    "        for i in np.arange(19):\n",
    "            sigbufs[i, :] = f.readSignal(i)\n",
    "        sigbufs[19, :] = f.readSignal(20)\n",
    "    else:\n",
    "        for i in np.arange(n):\n",
    "            sigbufs[i, :] = f.readSignal(i)\n",
    "\n",
    "    time = [1/f.samplefrequency(0) * i for i in range(len(sigbufs[0]))]\n",
    "\n",
    "    annotations = f.readAnnotations()  \n",
    "\n",
    "\n",
    "    new_annot = [(annotations[0][i], annotations[1][i], annotations[2][i])  \n",
    "                 for i in range(len(annotations[0])) \n",
    "                                if (annotations[1][i] > 0) and (annotations[2][i] in [\"Ð´Ð°Ð±Ð» Ñ\\x81Ð¿Ð°Ð¹Ðº\", \"*\", \"?\", \"F7\", \"F7(blockUserBlock)\", 'Ñ\\x8dÐ°'])]\n",
    "    f.close()\n",
    "    return sigbufs, new_annot, time, f.samplefrequency(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f212e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:02:39.313022Z",
     "start_time": "2024-12-03T12:02:38.089556Z"
    }
   },
   "outputs": [],
   "source": [
    "record_names = [\"DataToLabel/P7.edf\", \n",
    "               \"DataToLabel/P13.edf\", \n",
    "               \"DataToLabel/P14.edf\", \n",
    "               \"DataToLabel/P15.edf\", \n",
    "               \"DataToLabel/P16.edf\", \n",
    "               \"DataToLabel/P17.edf\", \n",
    "               \"DataToLabel/P18.edf\", \n",
    "               \"DataToLabel/P19.edf\"]\n",
    "\n",
    "records = []\n",
    "annots = []\n",
    "times = []\n",
    "freqs = []\n",
    "for file_name in record_names:\n",
    "\n",
    "    sigbufs, new_annot, time, freq = ReadSignal(file_name)\n",
    "    records.append(sigbufs)\n",
    "    annots.append(new_annot)\n",
    "    times.append(time)\n",
    "    freqs.append(freq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fcf85ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:02:42.973051Z",
     "start_time": "2024-12-03T12:02:42.968482Z"
    }
   },
   "outputs": [],
   "source": [
    "def NormalizeAndClip(data):\n",
    "    for i in tqdm(range(len(data))):\n",
    "        signal = data[i]\n",
    "        means = signal.mean(axis=1)[..., None]\n",
    "        stds = signal.std(axis=1)[..., None]\n",
    "        signal = np.clip((signal - means) / stds, a_min=-10, a_max=10)\n",
    "        data[i] = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbaa22e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:02:44.953281Z",
     "start_time": "2024-12-03T12:02:44.643714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 26.70it/s]\n"
     ]
    }
   ],
   "source": [
    "NormalizeAndClip(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b03c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:03:37.726509Z",
     "start_time": "2024-12-03T12:03:37.697110Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for record in records:\n",
    "    test_data.append(torch.FloatTensor(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c92233a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:03:41.001520Z",
     "start_time": "2024-12-03T12:03:40.966218Z"
    },
    "code_folding": [
     0,
     15,
     37,
     53
    ]
   },
   "outputs": [],
   "source": [
    "class conbr_block(nn.Module):\n",
    "    def __init__(self, in_layer, out_layer, kernel_size, stride, dilation):\n",
    "        super(conbr_block, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_layer, out_layer, kernel_size=kernel_size, stride=stride, dilation = dilation, padding = 3, bias=True)\n",
    "        self.bn = nn.BatchNorm1d(out_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        out = self.relu(x)\n",
    "        \n",
    "        return out       \n",
    "\n",
    "class se_block(nn.Module):\n",
    "    def __init__(self,in_layer, out_layer):\n",
    "        super(se_block, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_layer, out_layer//8, kernel_size=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(out_layer//8, in_layer, kernel_size=1, padding=0)\n",
    "        self.fc = nn.Linear(1,out_layer//8)\n",
    "        self.fc2 = nn.Linear(out_layer//8,out_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        x_se = nn.functional.adaptive_avg_pool1d(x,1)\n",
    "        x_se = self.conv1(x_se)\n",
    "        x_se = self.relu(x_se)\n",
    "        x_se = self.conv2(x_se)\n",
    "        x_se = self.sigmoid(x_se)\n",
    "        \n",
    "        x_out = torch.add(x, x_se)\n",
    "        return x_out\n",
    "\n",
    "class re_block(nn.Module):\n",
    "    def __init__(self, in_layer, out_layer, kernel_size, dilation):\n",
    "        super(re_block, self).__init__()\n",
    "        \n",
    "        self.cbr1 = conbr_block(in_layer,out_layer, kernel_size, 1, dilation)\n",
    "        self.cbr2 = conbr_block(out_layer,out_layer, kernel_size, 1, dilation)\n",
    "        self.seblock = se_block(out_layer, out_layer)\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        x_re = self.cbr1(x)\n",
    "        x_re = self.cbr2(x_re)\n",
    "        x_re = self.seblock(x_re)\n",
    "        x_out = torch.add(x, x_re)\n",
    "        return x_out          \n",
    "\n",
    "class UNET_1D(nn.Module):\n",
    "    def __init__(self ,input_dim,layer_n,kernel_size,depth):\n",
    "        super(UNET_1D, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.layer_n = layer_n\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depth = depth\n",
    "        \n",
    "        self.AvgPool1D1 = nn.AvgPool1d(input_dim, stride=5, padding=8)\n",
    "        self.AvgPool1D2 = nn.AvgPool1d(input_dim, stride=25, padding=8)\n",
    "        self.AvgPool1D3 = nn.AvgPool1d(input_dim, stride=125, padding=8)\n",
    "        \n",
    "        self.layer1 = self.down_layer(self.input_dim, self.layer_n, self.kernel_size,1, 2)\n",
    "        self.layer2 = self.down_layer(self.layer_n, int(self.layer_n*2), self.kernel_size,5, 2)\n",
    "        self.layer3 = self.down_layer(int(self.layer_n*2)+int(self.input_dim), int(self.layer_n*3), self.kernel_size,5, 2)\n",
    "        self.layer4 = self.down_layer(int(self.layer_n*3)+int(self.input_dim), int(self.layer_n*4), self.kernel_size,5, 2)\n",
    "        self.layer5 = self.down_layer(int(self.layer_n*4)+int(self.input_dim), int(self.layer_n*5), self.kernel_size,4, 2)\n",
    "\n",
    "        self.cbr_up1 = conbr_block(int(self.layer_n*7), int(self.layer_n*3), self.kernel_size, 1, 1)\n",
    "        self.cbr_up2 = conbr_block(int(self.layer_n*5), int(self.layer_n*2), self.kernel_size, 1, 1)\n",
    "        self.cbr_up3 = conbr_block(int(self.layer_n*3), self.layer_n, self.kernel_size, 1, 1)\n",
    "        self.upsample = nn.Upsample(scale_factor=5, mode='nearest')\n",
    "        self.upsample1 = nn.Upsample(scale_factor=5, mode='nearest') #for 4000 it is 5 and for 100 is 4\n",
    "        \n",
    "        self.outcov = nn.Conv1d(self.layer_n, 2, kernel_size=self.kernel_size, stride=1,padding = 3)\n",
    "    \n",
    "        \n",
    "    def down_layer(self, input_layer, out_layer, kernel, stride, depth):\n",
    "        block = []\n",
    "        block.append(conbr_block(input_layer, out_layer, kernel, stride, 1))\n",
    "        for i in range(depth):\n",
    "            block.append(re_block(out_layer,out_layer,kernel,1))\n",
    "        return nn.Sequential(*block)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        pool_x1 = self.AvgPool1D1(x)\n",
    "\n",
    "        \n",
    "        pool_x2 = self.AvgPool1D2(x)\n",
    "\n",
    "        \n",
    "        pool_x3 = self.AvgPool1D3(x)\n",
    "\n",
    "        \n",
    "        \n",
    "        #############Encoder#####################\n",
    "        \n",
    "        out_0 = self.layer1(x)\n",
    "\n",
    "        out_1 = self.layer2(out_0)        \n",
    "\n",
    "        \n",
    "        \n",
    "        x = torch.cat([out_1,pool_x1],1)\n",
    "\n",
    "\n",
    "        out_2 = self.layer3(x)\n",
    "\n",
    "        \n",
    "        x = torch.cat([out_2,pool_x2],1)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        \n",
    "        \n",
    "        #############Decoder####################\n",
    "        \n",
    "        up = self.upsample1(x)\n",
    "        \n",
    "        up = torch.cat([up,out_2],1)\n",
    "\n",
    "        \n",
    "        up = self.cbr_up1(up)\n",
    "\n",
    "        \n",
    "        up = self.upsample(up)\n",
    "  \n",
    "        \n",
    "        up = torch.cat([up,out_1],1)\n",
    "\n",
    "        \n",
    "        up = self.cbr_up2(up)\n",
    "\n",
    "        \n",
    "        \n",
    "        up = self.upsample(up)\n",
    "\n",
    "        \n",
    "        up = torch.cat([up,out_0],1)\n",
    "\n",
    "        \n",
    "        up = self.cbr_up3(up)\n",
    "        \n",
    "        out = self.outcov(up)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e81ac63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:03:41.830659Z",
     "start_time": "2024-12-03T12:03:41.822184Z"
    }
   },
   "outputs": [],
   "source": [
    "def CollectingPreds(model, test_data):\n",
    "\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    all_preds = []\n",
    "    for i in range(len(test_data)):\n",
    "        record_preds = []\n",
    "        for idx in tqdm(range(OVERLAP, test_data[i].size()[1]- RECEPTIVE_FIELD - OVERLAP, RECEPTIVE_FIELD)):\n",
    "\n",
    "            train_seq = test_data[i][:, idx-OVERLAP:idx+RECEPTIVE_FIELD+OVERLAP][None, ...]\n",
    "                  \n",
    "            out = model(train_seq)\n",
    "            m = nn.Softmax(dim=1)\n",
    "            out = m(out)\n",
    "            \n",
    "            preds = np.argmax(out.detach().cpu().numpy(), axis=1)\n",
    "            record_preds.append(preds)\n",
    "        shapes = np.array(record_preds).shape\n",
    "        record_preds = np.array(record_preds).reshape(shapes[0] * shapes[1] * shapes[2])\n",
    "        all_preds.append(record_preds)\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aaedfb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:03:43.775854Z",
     "start_time": "2024-12-03T12:03:43.764224Z"
    }
   },
   "outputs": [],
   "source": [
    "def MergeClose(predictions, threshold):\n",
    "    i = 0\n",
    "    in_event = False\n",
    "    while i < len(predictions):\n",
    "        while i < len(predictions) and predictions[i] == 1:\n",
    "            in_event = True\n",
    "            i += 1\n",
    "        if  i < len(predictions) and in_event:\n",
    "            if np.any(predictions[i:i+threshold]):\n",
    "                while  i < len(predictions) and predictions[i] == 0:\n",
    "                    predictions[i] = 1\n",
    "                    i += 1\n",
    "            else:\n",
    "                in_event = False\n",
    "        i += 1\n",
    "\n",
    "def DeleteShortEvents(predictions, threshold):\n",
    "    i = 0\n",
    "    while i < len(predictions):\n",
    "        event_len = 0\n",
    "        event_idx_start = i\n",
    "        while i < len(predictions) and predictions[i] == 1:\n",
    "            i += 1\n",
    "            event_len += 1\n",
    "        if event_len < threshold:\n",
    "            predictions[event_idx_start:i] = 0\n",
    "        i += 1\n",
    "def PostProcessing(predictions, threshold1, threshold2=None):\n",
    "    MergeClose(predictions, threshold1)\n",
    "    if threshold2 is None:\n",
    "        DeleteShortEvents(predictions, threshold1)\n",
    "    else:\n",
    "        DeleteShortEvents(predictions, threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "949f8cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:33:40.254117Z",
     "start_time": "2024-12-03T12:33:24.324327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.11it/s]\n",
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.46it/s]\n",
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.25it/s]\n",
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.38it/s]\n",
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.64it/s]\n",
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.75it/s]\n",
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.87it/s]\n",
      "100%|██████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.76it/s]\n"
     ]
    }
   ],
   "source": [
    "OVERLAP = 0\n",
    "RECEPTIVE_FIELD = 4000\n",
    "model = UNET_1D(20,128,7,3)\n",
    "model.load_state_dict(torch.load(\"./CrossValidationResults/13RecordsNormalized/Split2/Unet1d\"))  \n",
    "all_preds = CollectingPreds(model, test_data)\n",
    "threshold = 20 #low because of lower sample rate, for 500 need to up to 30\n",
    "    \n",
    "for j in range(len(all_preds)):\n",
    "    PostProcessing(all_preds[j], threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42a60e05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:33:41.113819Z",
     "start_time": "2024-12-03T12:33:41.108607Z"
    }
   },
   "outputs": [],
   "source": [
    "def CreateNewAnnotation(time_start, labels, freq): \n",
    "    freq = 1/freq\n",
    "    i = 0\n",
    "    label_starts = [time_start]\n",
    "    label_lens = [-1]\n",
    "    desc = [\"StartPredictionTime\"]\n",
    "    while i < len(labels):\n",
    "        if labels[i] == 1:\n",
    "            desc.append(\"ModelPrediction\")\n",
    "            label_starts.append(time_start + i*freq)\n",
    "            cur_start = i\n",
    "            while labels[i] == 1:\n",
    "                i += 1\n",
    "            label_lens.append((i - cur_start) * freq)\n",
    "        i += 1\n",
    "    label_starts += [time_start + i*freq]\n",
    "    label_lens += [-1]\n",
    "    desc += [\"EndPredictionTime\"]\n",
    "\n",
    "    return np.array(label_starts), np.array(label_lens), np.array(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83309874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:33:42.034885Z",
     "start_time": "2024-12-03T12:33:42.022727Z"
    }
   },
   "outputs": [],
   "source": [
    "def WriteEDF(predictions, freq):\n",
    "    \n",
    "    for i in range(len(record_names)):\n",
    "        time_start = 0\n",
    "        \n",
    "        preds_annotations = CreateNewAnnotation(time_start, predictions[i], freq)\n",
    "        data = mne.io.read_raw_edf(record_names[i])\n",
    "\n",
    "        preds_annotations = list(preds_annotations)\n",
    "        preds_annotations[1] = np.clip(preds_annotations[1], a_min=0, a_max = None)\n",
    "\n",
    "        old_annot = np.array([[data.annotations[i][\"onset\"], data.annotations[i][\"duration\"], data.annotations[i][\"description\"]] \n",
    "                      for i in range(len(data.annotations))])\n",
    "        \n",
    "        full_annot = np.concatenate([np.array(preds_annotations), old_annot.T], axis=1)\n",
    "        annotations = mne.Annotations(np.array(full_annot)[0], np.array(full_annot)[1], np.array(full_annot)[2])\n",
    "        \n",
    "        data.set_annotations(annotations)\n",
    "        \n",
    "        data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n",
    "        data.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "463e5d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:33:44.730842Z",
     "start_time": "2024-12-03T12:33:43.659368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P7.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Overwriting existing file.\n",
      "Reading 0 ... 121588  =      0.000 ...   609.455 secs...\n",
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Overwriting existing file.\n",
      "Reading 0 ... 121389  =      0.000 ...   608.458 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Overwriting existing file.\n",
      "Reading 0 ... 120593  =      0.000 ...   604.468 secs...\n",
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P15.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 120991  =      0.000 ...   606.463 secs...\n",
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P16.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Overwriting existing file.\n",
      "Reading 0 ... 120991  =      0.000 ...   606.463 secs...\n",
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P17.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Overwriting existing file.\n",
      "Reading 0 ... 121986  =      0.000 ...   611.450 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P18.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Overwriting existing file.\n",
      "Reading 0 ... 120593  =      0.000 ...   604.468 secs...\n",
      "Extracting EDF parameters from /mnt/hdd-home/gromov_n/extreme-events/EEG seizure/EpiActivity/DataToLabel/P19.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n",
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n",
      "/tmp/ipykernel_1019228/1133601270.py:7: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(record_names[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Reading 0 ... 120593  =      0.000 ...   604.468 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1019228/1133601270.py:20: RuntimeWarning: Data has a non-integer sampling rate of 199.50274692224406; writing to EDF format may cause a small change to sample times.\n",
      "  data.export(\"DataToLabel/Preds_\" + record_names[i].split(\"/\")[1], overwrite=True)\n"
     ]
    }
   ],
   "source": [
    "WriteEDF(all_preds, freqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b96639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
